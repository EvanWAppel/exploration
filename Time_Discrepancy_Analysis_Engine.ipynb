{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Time Discrepancy Analysis Engine.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EvanWAppel/exploration/blob/master/Time_Discrepancy_Analysis_Engine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNDOdMzRq-Hu"
      },
      "source": [
        "# Time Discrepancy Analysis Engine\n",
        "\n",
        "This Python notebook is designed to compile and analyze several sets of data and to produce tools for discovering discrepancies.\n",
        "\n",
        "When run, the engine will produce an excel file with its findings.\n",
        "\n",
        "Production note: Started working on this on September 7. In one month I have a viable product."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKBHz59czi0Q"
      },
      "source": [
        "## Step 1:\n",
        "\n",
        "Upload data. \n",
        "\n",
        "Files need to be named thusly:\n",
        "\n",
        "1.   employee_file\n",
        "2.   exceptions\n",
        "3.   schedule\n",
        "4.   project\n",
        "5.   sessions\n",
        "6.   slices\n",
        "\n",
        "This can be accomplished by uploading directly into the content folder or by using the following code to prompt a set of uploads. (Activate the next cell's code to use the prompts.)\n",
        "\n",
        "## Step 2:\n",
        "\n",
        "Run the Engine. Click \"Runtime\" in the toolbar. Then click \"Run All.\"\n",
        "\n",
        "## Step 3: \n",
        "\n",
        "Download the file.\n",
        "\n",
        "## More information?\n",
        "\n",
        "For more information, please see the following cell which details specifications. If you can't find what you're looking for, please call Evan Appel at 702-466-4498.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lYQj1ve_3V0"
      },
      "source": [
        "# Documentation\n",
        "\n",
        "The output Excel file has many sheets in it, each are described here:\n",
        "\n",
        "1. employeeFile\n",
        "\n",
        "      File downloaded from Bamboo. Contains basic information about the employee such as their EID, name, date of hire, job title, and division.\n",
        "\n",
        "2. projectData\n",
        "\n",
        "      File downloaded from OnTime. Not all data sets have reliable project data and as such, that column cannot be used in every analysis document. Hence why we have an RA Analysis and a Project Analysis.\n",
        "\n",
        "3. exceptionList\n",
        "4. schedule\n",
        "5. voxcoSessions\n",
        "6. onTimeSlices\n",
        "7. RAandDateAnalysis\n",
        "8. projectandRAAnalysis\n",
        "9. morningPadding\n",
        "10. eveningPadding\n",
        "11. excessiveBreaks\n",
        "12. toomuchinnerpadding\n",
        "13. attendanceVariance\n",
        "14. histogramsAndScatterPlots\n",
        "15. projectComparison\n",
        "16. departmentAnalysis\n",
        "18. nonRAAnalysis\n",
        "19. exception analysis\n",
        "20. Inconsistent project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldsKChydQ2oS"
      },
      "source": [
        "#Query References\n",
        "##Sessions Query\n",
        "\n",
        "```\n",
        "\n",
        " /*TITLE: Agent Sessions Query\n",
        "   AUTHOR: Evan Appel\n",
        "   UPDATED: May 7, 2020*/\n",
        " \n",
        "        SELECT LOWER(a.FirstName + ' ' + a.LastName) AS agent\n",
        "             , LEFT(dirsrv.text,PATINDEX('% %',dirsrv.text)) AS bamboo_id\n",
        "             , o2.Name AS project_name\n",
        "             -- The following sets the login and logout times to ISO 8601 for coding purposes\n",
        "             /*, FORMAT(s.loginDateTime,'yyyy-MM-ddTHH:mm:ss.fffZ') AS LOGIN\n",
        "             , FORMAT(s.logoutDateTime, 'yyyy-MM-ddTHH:mm:ss.fffZ') AS logout */\n",
        "             , CAST(DATEADD(ss,DATEDIFF(ss,GETUTCDATE(), GETDATE()),s.loginDateTime) AS DATE) AS LOGIN_DATE\n",
        "             , CAST(DATEADD(ss,DATEDIFF(ss,GETUTCDATE(), GETDATE()),s.loginDateTime) AS TIME) AS lOGIN_TIME\n",
        "             , CAST(DATEADD(ss,DATEDIFF(ss,GETUTCDATE(), GETDATE()),s.logoutDateTime) AS DATE) AS LOGOUT_DATE\n",
        "             , CAST(DATEADD(ss,DATEDIFF(ss,GETUTCDATE(), GETDATE()),s.logoutDateTime) AS TIME) AS LOGOUT_TIME\n",
        "             , DATEDIFF(ms, s.loginDateTime, s.logoutDateTime)/1000 AS sesh_dur\n",
        "             , [talkTime]\n",
        "             , [waitingTime]\n",
        "             , [pauseTime]\n",
        "             , [reviewTime]\n",
        "             , [talkTime] + [waitingTime] + [pauseTime] + [reviewTime] AS soat \n",
        "            -- , ap.total AS completes\n",
        "             --, (((DATEDIFF(ms, s.loginDateTime, s.logoutDateTime)/1000)  / ap.total) / 60) AS prod_rate\n",
        "           /* */\n",
        "          FROM [VoxcoSystem].[dbo].[AgentSession] s\n",
        "     LEFT JOIN [VoxcoSystem].[dbo].[tblAgents] a \n",
        "            ON s.userId = a.k_Id\n",
        "     LEFT JOIN [VoxcoSystem].[dbo].[tblObjects] o \n",
        "            ON s.projectId = o.k_Id\n",
        "     LEFT JOIN [VoxcoSystem].[dbo].[tblObjects] o2 \n",
        "            ON o.ParentId = o2.k_Id\n",
        "     LEFT JOIN [VoxcoSystem].[dbo].[History_DirSrvObjName] dirsrv\n",
        "            ON s.userId = dirsrv.id\n",
        "     LEFT JOIN [VoxcoSystem].[dbo].[AgentSessionConnectionTimes] c \n",
        "            ON s.sessionId = c.sessionId\n",
        "     --LEFT JOIN (SELECT * FROM [VoxcoSystem].[dbo].[AgentSessionProductivity]\n",
        "               --  WHERE resultCode = 'CO') ap\n",
        "           -- ON s.sessionId = ap.sessionId\n",
        "            -- Date parameter set to yesterday, local time.\n",
        "         WHERE CAST(DATEADD(ss,DATEDIFF(ss,GETUTCDATE(), GETDATE()),s.loginDateTime) AS DATE) BETWEEN '2021-08-28' AND '2021-09-03' -- weekend code\n",
        "        -- CAST(DATEADD(ss,DATEDIFF(ss,GETUTCDATE(), GETDATE()),s.loginDateTime) AS DATE) = CAST(getdate() - 1 AS DATE) \n",
        "          -- and a.FirstName = 'richard'\n",
        "      ORDER BY loginDateTime DESC\n",
        "```\n",
        "##Slices Query\n",
        "Use in Cloudwatch, prod event bus\n",
        "\n",
        "```\n",
        "fields @timestamp, detail.associate, detail.start, detail.end, detail.minutes, detail.punch, detail.project, `detail.slice-type`\n",
        "| filter (`detail-type` = \"slice\") \n",
        "and `detail.slice-type` not like \"epoch\" \n",
        "and `detail.punch` not in [\"out\",\"manager\",\"courtesy-patrol\",\"monitoring\",\"team-lead-assistant\",\"office-maintenance\",\"office-technician\",\"office-admin\",\"trainer\",\"quota-managemeent\",\"\"]\n",
        "and strlen(`detail.punch`) >=1\n",
        "| sort @timestamp desc\n",
        "|limit 10000\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcfO9P0KClv5"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZ2iMHwoCSmc"
      },
      "source": [
        "import pandas as pd\n",
        "import datetime as datetime\n",
        "import pytz \n",
        "from dateutil import parser\n",
        "import numpy as np\n",
        "from google.colab import files"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juxubUrIhGeG"
      },
      "source": [
        "# Options and Settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lM1Z24EiatFN"
      },
      "source": [
        "#Sets options so the data frame doesn't break into \"pages\"\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', 800)\n",
        "# When I assign a column to itself to change its datatype to datetime it throws a warning, this suppresses that warning. #### USE EXTREME CAUTION\n",
        "pd.set_option('mode.chained_assignment', None)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RY1c3QrQozP"
      },
      "source": [
        "# Table Diagnostic Tool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GPoV9plC1ha"
      },
      "source": [
        "# Ingesters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHQtYLoFC8iJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b50e64b-210d-4b41-d97e-00c59746956b"
      },
      "source": [
        "# Employee Data\n",
        "try:\n",
        "  employeeFile = pd.read_csv('employee_file.csv', parse_dates=True)\n",
        "except:\n",
        "  print(\"No Employee File Available\")\n",
        "else:\n",
        "  print(\"Employee File checker ...\")\n",
        "  checker = 0\n",
        "  if len(employeeFile) > 0:\n",
        "    print(\"Employee File is non-empty. \"+str(len(employeeFile))+\" records found.\")\n",
        "  else:\n",
        "    print(\"Employee File problem: Empty File! \"+str(len(employeeFile))+\" records found.\")\n",
        "  for i in employeeFile.columns :\n",
        "    if i in ['Last name, First name', 'Employee #', 'Status', 'Division', 'Job Title','Hire Date']:\n",
        "      checker += 1\n",
        "  if checker == 6:\n",
        "    print(\"Required columns present for Employee File\")\n",
        "  else:\n",
        "    print(\"Check Employee File document for correct fields, referenced above.\")\n",
        "# Exception Data\n",
        "try:\n",
        "  exceptions = pd.read_csv('exceptions.csv', parse_dates=True)\n",
        "except:\n",
        "  print(\"No exceptions file Available\")\n",
        "else:\n",
        "  print(\"Exceptions file checker ...\")\n",
        "  if len(exceptions) > 0:\n",
        "    print(\"Employee File is non-empty. \"+str(len(exceptions))+\" reecords found.\")\n",
        "  else:\n",
        "    print(\"Employee File is empty! \"+str(len(exceptions))+\" records found.\")\n",
        "  print(\"Data begins on \"+str(exceptions['date'].min())+\"\\n\"+\"And ends on \"+str(exceptions['date'].max()))\n",
        "# Schedule Data\n",
        "try:\n",
        "  schedule = pd.read_csv('schedule.csv')\n",
        "except:\n",
        "  print(\"No schedule file Available\")\n",
        "else:\n",
        "  print(\"Schedule file checker ...\")\n",
        "  if len(schedule) > 0:\n",
        "    print(\"Schedule File is non-empty. \"+str(len(schedule))+\" reecords found.\")\n",
        "  else:\n",
        "    print(\"Schedule File is empty! \"+str(len(schedule))+\" records found.\")\n",
        "  print(\"Data begins on \"+str(schedule['Date'].min())+\"\\n\"+\"And ends on \"+str(schedule['Date'].max()))\n",
        "# Sessions Data\n",
        "try:\n",
        "  sessions = pd.read_excel('sessions.xlsx', parse_dates=True)\n",
        "except:\n",
        "  print(\"No sessions file Available\")\n",
        "else:\n",
        "  print(\"Sessions file checker ...\")\n",
        "  if len(sessions) > 0:\n",
        "    print(\"Sessions File is non-empty. \"+str(len(sessions))+\" records found.\")\n",
        "  else:\n",
        "    print(\"Sessions File is empty! \"+str(len(sessions))+\" records found.\")\n",
        "  print(\"Data begins on \"+str(sessions['LOGIN_DATE'].min())+\"\\n\"+\"And ends on \"+str(sessions['LOGIN_DATE'].max()))\n",
        "# Slices Data\n",
        "try:\n",
        "  slices = pd.read_csv('slices.csv', parse_dates=True)\n",
        "except:\n",
        "  print(\"No slices file Available\")\n",
        "else:\n",
        "  print(\"Slices file checker ...\")\n",
        "  if len(slices) > 0:\n",
        "    print(\"Slices File is non-empty. \"+str(len(slices))+\" records found.\")\n",
        "  else:\n",
        "    print(\"Slices File is empty! \"+str(len(schedule))+\" records found.\")\n",
        "  print(\"Data begins on \"+str(slices['detail.start'].min())+\"\\n\"+\"And ends on \"+str(slices['detail.start'].max()))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Employee File checker ...\n",
            "Employee File is non-empty. 509 records found.\n",
            "Required columns present for Employee File\n",
            "Exceptions file checker ...\n",
            "Employee File is non-empty. 527 reecords found.\n",
            "Data begins on 2021-09-29\n",
            "And ends on 2021-10-05\n",
            "Schedule file checker ...\n",
            "Schedule File is non-empty. 339 reecords found.\n",
            "Data begins on 2021-09-29\n",
            "And ends on 2021-10-05\n",
            "Sessions file checker ...\n",
            "Sessions File is non-empty. 550 records found.\n",
            "Data begins on 2021-09-29 00:00:00\n",
            "And ends on 2021-10-05 00:00:00\n",
            "Slices file checker ...\n",
            "Slices File is non-empty. 9760 records found.\n",
            "Data begins on 2021-07-28T00:54:22.954075Z\n",
            "And ends on 2021-10-06T03:37:47.280888Z\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Pqt4aC4QoGD"
      },
      "source": [
        "def diag(x,y,z):\n",
        "  # x == dataframe you wish to analyze\n",
        "  # y == mode you wish to use\n",
        "  ## y == RA == RA search mode, returns info about an EID entered into the z position\n",
        "  # z == mode parameter A\n",
        "  if y == None and z == None:\n",
        "    print(x.dtypes)\n",
        "    print(x.describe())\n",
        "    print(x.head(50))\n",
        "  if y == \"RA\":\n",
        "    try:\n",
        "      table = x[x[\"eid\"]==z]\n",
        "      print(table.dtypes)\n",
        "      print(table.describe())\n",
        "      print(table.head(50))\n",
        "    except: \n",
        "      print(\"No eid found\")\n",
        "\n",
        "# Test\n",
        "#diag(metrics,\"RA\",100045)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5_uBkkTiT9O"
      },
      "source": [
        "# Table Preparation\n",
        "This part is to get table data types arranged properly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owei9F9RSmY7"
      },
      "source": [
        "### Employee File\n",
        "# Only Relevant Columns\n",
        "employee = employeeFile[[\"Last name, First name\",\"Employee #\",\"Status\",\"Division\",\"Job Title\",\"Hire Date\"]]\n",
        "# Better column names\n",
        "employee = employee.rename(columns={\"Last name, First name\":\"full_name\",\n",
        "                                    \"Employee #\": \"eid\",\n",
        "                                    \"Hire Date\": \"hire_date\"})\n",
        "# Set hire date to proper date type\n",
        "employee[\"hire_date\"] = pd.to_datetime(employee[\"hire_date\"])\n",
        "# Diagnostics\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoNRCQdmIJZa"
      },
      "source": [
        "### Exceptions\n",
        "# Only Relevant columns\n",
        "excep = exceptions[[\"eid\",\"date\",\"project\",\"id\"]]\n",
        "# Set Date to proper type\n",
        "excep[\"date\"] = pd.to_datetime(excep[\"date\"])\n",
        "# Aggregate\n",
        "excep = excep.groupby([\"eid\",\"date\",\"project\"], as_index=False)[\"id\"].size().fillna(0)\n",
        "excep = excep.rename(columns={\"size\":\"exception_count\"})\n",
        "excep = excep[[\"eid\",\"date\",\"exception_count\"]]\n",
        "# Diagnostics\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEny8fPYYhry"
      },
      "source": [
        "### Schedule\n",
        "# Only Relevant Columns\n",
        "sched = schedule[[\"EID\",\"Project Name\",\"Date\",\"StartTime\",\"EndTime\"]]\n",
        "# column names are to be descriptive, undercase and words separated by underscores\n",
        "sched = sched.rename(columns={\"EID\":\"eid\",\n",
        "                              \"Project Name\":\"sched_project\",\n",
        "                              \"Date\":\"date\",\n",
        "                              \"StartTime\":\"sched_start\",\n",
        "                              \"EndTime\":\"sched_end\"})\n",
        "# Convert the datetimes to proper types. WARNING: Had to disable a warning for the following 3 rows. Note in above section.\n",
        "sched[\"sched_start\"] = pd.to_datetime(sched[\"date\"] + \" \" + sched[\"sched_start\"])\n",
        "sched[\"sched_end\"] = pd.to_datetime(sched[\"date\"] + \" \" + sched[\"sched_end\"])\n",
        "sched[\"date\"] = pd.to_datetime(sched[\"date\"])\n",
        "# Diagnostics\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZ62fL-ZZ7bX"
      },
      "source": [
        "### Sessions\n",
        "# Relevant Columns\n",
        "sesh = sessions[[\"bamboo_id\",\"project_name\",\"LOGIN_DATE\",\"lOGIN_TIME\",\"LOGOUT_DATE\",\"LOGOUT_TIME\",\"sesh_dur\",\"talkTime\",\"waitingTime\",\"pauseTime\",\"reviewTime\",\"soat\"]]\n",
        "# Rename Columns\n",
        "sesh = sesh.rename(columns={\"bamboo_id\":\"eid\",\n",
        "                            \"project_name\":\"vc_project\",\n",
        "                            \"talkTime\":\"talk_time\",\n",
        "                            \"waitingTime\":\"waiting_time\",\n",
        "                            \"pauseTime\":\"pause_time\",\n",
        "                            \"reviewTime\":\"review_time\"})\n",
        "# Correct Datatypes\n",
        "# To get the dates working: basically, the date and time need to be converted to strings and then concatenated, from there, a UTC suffix can be added with the first tz_localize, converted to Pacific time, and then remove the suffix with the second tz_localize\n",
        "sesh[\"vc_login\"] = pd.to_datetime(sesh[\"LOGIN_DATE\"].astype(str) + \" \" + sesh['lOGIN_TIME'].astype(str)).dt.tz_localize(\"US/Pacific\").dt.tz_localize(None)\n",
        "sesh[\"vc_logout\"] = pd.to_datetime(sesh[\"LOGOUT_DATE\"].astype(str) + \" \" + sesh['LOGOUT_TIME'].astype(str)).dt.tz_localize(\"US/Pacific\").dt.tz_localize(None)\n",
        "sesh[\"date\"] = sesh[\"vc_login\"].dt.date\n",
        "sesh[\"eid\"] = sesh[\"eid\"].fillna(0)\n",
        "sesh = sesh[sesh[\"eid\"] != '26045B']\n",
        "sesh = sesh[sesh[\"eid\"] != 'jleejoyce']\n",
        "sesh = sesh[sesh[\"eid\"] != 'kbigelow']\n",
        "sesh[\"eid\"] = sesh[\"eid\"].astype(\"str\").astype(\"int64\")\n",
        "# Diagnostics\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LD6fD0vtV9Kf"
      },
      "source": [
        "### Slices\n",
        "# Relevant Columns\n",
        "sl = slices[[\"detail.associate\",\"detail.start\",\"detail.end\",\"detail.minutes\",\"detail.punch\",\"detail.project\"]]\n",
        "# Rename Columns\n",
        "sl = sl.rename(columns={\"detail.associate\":\"eid\",\n",
        "                        \"detail.start\":\"ontime_start\",\n",
        "                        \"detail.end\":\"ontime_end\",\n",
        "                        \"detail.minutes\":\"ontime_duration\",\n",
        "                        \"detail.punch\":\"punch\",\n",
        "                        \"detail.project\":\"ontime_project\"})\n",
        "# Data Type Correction\n",
        "sl[\"eid\"] = sl[\"eid\"].astype(\"int64\")\n",
        "sl[\"ontime_start\"] = pd.to_datetime(sl[\"ontime_start\"]).dt.tz_convert(\"US/Pacific\").dt.tz_localize(None)\n",
        "sl[\"ontime_end\"] = pd.to_datetime(sl[\"ontime_end\"]).dt.tz_convert(\"US/Pacific\").dt.tz_localize(None)\n",
        "sl[\"date\"] = sl[\"ontime_start\"].dt.date\n",
        "# Data Cleaning\n",
        "# Rows with NAN in certain columns indicate a correction that hasn't been filtered by Cloudwatch\n",
        "sl = sl.dropna()\n",
        "#Diagnostics\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZK5kyVO5WaIp"
      },
      "source": [
        "# Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpf4xH0lWYCc",
        "outputId": "64ac7811-bb48-4eba-9f7f-f6f58221ee8c"
      },
      "source": [
        "################################################################### Schedule\n",
        "# The entire table is based on who should be here, which is determined by the schedule\n",
        "metrics = sched[[\"eid\",\"sched_project\",\"date\",\"sched_start\",\"sched_end\"]]\n",
        "\n",
        "################################################################### Employee\n",
        "# Add employee information\n",
        "metrics = pd.merge(metrics,employee,on=[\"eid\"],how=\"left\")\n",
        "\n",
        "################################################################### Exceptions\n",
        "# Add in how many exceptions they filed\n",
        "metrics = pd.merge(metrics,excep,on=[\"eid\",\"date\"],how=\"left\").fillna(0)\n",
        "\n",
        "################################################################### Voxco\n",
        "# First Voxco Login\n",
        "# Figure out the first voxco login by person/date\n",
        "firstVC = sesh.groupby([\"eid\",\"date\"],as_index=False).agg({\"vc_login\":min})\n",
        "# prepare the list of projects\n",
        "vcProjectIn = sesh[[\"eid\",\"date\",\"vc_login\",\"vc_project\" ]]\n",
        "# rename project\n",
        "vcProjectIn = vcProjectIn.rename(columns={\"vc_project\":\"vc_login_project\"})\n",
        "# Join the project to the first login of the day so you only have the project for the first login\n",
        "firstVC = pd.merge(firstVC,vcProjectIn,on=[\"eid\",\"date\",\"vc_login\"],how=\"left\")\n",
        "# convert firstVC date to proper format\n",
        "firstVC[\"date\"] = pd.to_datetime(firstVC[\"date\"])\n",
        "# Join first login info\n",
        "metrics = pd.merge(metrics,firstVC,on=[\"eid\",\"date\"],how=\"left\")\n",
        "\n",
        "# Last Voxco Logout\n",
        "# Last logout \n",
        "lastVC = sesh.groupby([\"eid\",\"date\"],as_index=False).agg({\"vc_logout\":max})\n",
        "# Last logout project\n",
        "vcProjectOut = sesh[[\"eid\",\"date\",\"vc_logout\",\"vc_project\" ]]\n",
        "# rename project\n",
        "vcProjectOut = vcProjectOut.rename(columns={\"vc_project\":\"vc_logout_project\"})\n",
        "# Join project to logout\n",
        "lastVC = pd.merge(lastVC,vcProjectOut,on=[\"eid\",\"date\",\"vc_logout\"],how=\"left\")\n",
        "# convert lastVC date to proper format\n",
        "lastVC[\"date\"] = pd.to_datetime(lastVC[\"date\"])\n",
        "# Join last logout info\n",
        "metrics = pd.merge(metrics,lastVC,on=[\"eid\",\"date\"],how=\"left\")\n",
        "\n",
        "# Voxco Durations\n",
        "# sum up durations, project agnostic to fit the table\n",
        "vcTimes = sesh.groupby([\"eid\",\"date\"],as_index=False).agg({\"sesh_dur\":sum,\n",
        "                                                           \"soat\":sum,\n",
        "                                                           \"talk_time\":sum,\n",
        "                                                           \"waiting_time\":sum,\n",
        "                                                           \"pause_time\":sum,\n",
        "                                                           \"review_time\":sum})\n",
        "# Convert vcTimes date to correct format\n",
        "vcTimes[\"date\"] = pd.to_datetime(vcTimes[\"date\"])\n",
        "# Join durations\n",
        "metrics = pd.merge(metrics,vcTimes,on=[\"eid\",\"date\"],how=\"left\")\n",
        "\n",
        "# Voxco Count\n",
        "# count the sessions\n",
        "vcCount = sesh.groupby([\"eid\",\"date\"],as_index=False)[\"eid\"].size()\n",
        "# Convert vcCount date to proper format\n",
        "vcCount[\"date\"] = pd.to_datetime(vcCount[\"date\"])\n",
        "vcCount = vcCount.rename(columns={\"size\":\"vc_session_count\"})\n",
        "# Join count\n",
        "metrics = pd.merge(metrics,vcCount,on=[\"eid\",\"date\"],how=\"left\")\n",
        "\n",
        "################################################################### Slices\n",
        "# First OnTime Punch\n",
        "# Figure out the first OnTime Punch by person/date\n",
        "firstOT = sl.groupby([\"eid\",\"date\"],as_index=False).agg({\"ontime_start\":min})\n",
        "# prepare the list of projects\n",
        "otProjectIn = sl[[\"eid\",\"date\",\"ontime_start\",\"ontime_project\" ]]\n",
        "# rename project\n",
        "otProjectIn = otProjectIn.rename(columns={\"ontime_project\":\"ontime_start_project\"})\n",
        "# Join the project to the first punch of the day so you only have the project for the first punch\n",
        "firstOT = pd.merge(firstOT,otProjectIn,on=[\"eid\",\"date\",\"ontime_start\"],how=\"left\")\n",
        "# convert firstVC date to proper format\n",
        "firstOT[\"date\"] = pd.to_datetime(firstOT[\"date\"])\n",
        "# Join first login info\n",
        "metrics = pd.merge(metrics,firstOT,on=[\"eid\",\"date\"],how=\"left\")\n",
        "\n",
        "# Last OnTime Punch\n",
        "# Figure out the last OnTime Punch by person/date\n",
        "lastOT = sl.groupby([\"eid\",\"date\"],as_index=False).agg({\"ontime_end\":max})\n",
        "# prepare the list of projects\n",
        "otProjectOut = sl[[\"eid\",\"date\",\"ontime_end\",\"ontime_project\" ]]\n",
        "# rename project\n",
        "otProjectOut = otProjectOut.rename(columns={\"ontime_project\":\"ontime_end_project\"})\n",
        "# Join the project to the first punch of the day so you only have the project for the first punch\n",
        "lastOT = pd.merge(lastOT,otProjectOut,on=[\"eid\",\"date\",\"ontime_end\"],how=\"left\")\n",
        "# convert firstVC date to proper format\n",
        "lastOT[\"date\"] = pd.to_datetime(lastOT[\"date\"])\n",
        "# Join first login info\n",
        "metrics = pd.merge(metrics,lastOT,on=[\"eid\",\"date\"],how=\"left\")\n",
        "\n",
        "# Ontime Durations\n",
        "# sum up durations, project agnostic to fit the table\n",
        "otTimes = sl.groupby([\"eid\",\"date\"],as_index=False).agg({\"ontime_duration\":sum})\n",
        "# Convert otTimes date to correct format\n",
        "otTimes[\"date\"] = pd.to_datetime(otTimes[\"date\"])\n",
        "# Join durations\n",
        "metrics = pd.merge(metrics,otTimes,on=[\"eid\",\"date\"],how=\"left\")\n",
        "\n",
        "# OT Count\n",
        "# count the sessions\n",
        "otCount = sl.groupby([\"eid\",\"date\"],as_index=False)[\"eid\"].size()\n",
        "# Convert otCount date to proper format\n",
        "otCount[\"date\"] = pd.to_datetime(otCount[\"date\"])\n",
        "otCount = otCount.rename(columns={\"size\":\"ontime_slice_count\"})\n",
        "# Join count\n",
        "metrics = pd.merge(metrics,otCount,on=[\"eid\",\"date\"],how=\"left\")\n",
        "\n",
        "# OnTime Breaks\n",
        "breakData = sl[sl[\"punch\"]==\"break\"]\n",
        "breakCount = breakData.groupby([\"eid\",\"date\"],as_index=False).size()\n",
        "breakSum = breakData.groupby([\"eid\",\"date\"],as_index=False).agg({\"ontime_duration\":sum})\n",
        "breakData = pd.merge(breakCount,breakSum,on=[\"eid\",\"date\"],how=\"left\")\n",
        "breakData = breakData.rename(columns={\"ontime_duration\":\"break_duration\",\n",
        "                                      \"size\":\"break_count\"})\n",
        "breakData[\"date\"] = pd.to_datetime(breakData[\"date\"])\n",
        "metrics = pd.merge(metrics,breakData,on=[\"eid\",\"date\"],how=\"left\")\n",
        "\n",
        "################################################################### MOAR COLUMNS!!!\n",
        "# Diff between schedule start and ontime start\n",
        "metrics = metrics.assign(schedule_to_ontime=metrics[\"ontime_start\"] - metrics[\"sched_start\"])\n",
        "metrics[\"schedule_to_ontime\"] = metrics[\"schedule_to_ontime\"].dt.total_seconds()\n",
        "metrics[\"schedule_to_ontime\"] = metrics[\"schedule_to_ontime\"] / 60\n",
        "# Diff between ontime start and voxco start\n",
        "metrics = metrics.assign(ontime_to_voxco=metrics[\"vc_login\"] - metrics[\"ontime_start\"])\n",
        "metrics[\"ontime_to_voxco\"] = metrics[\"ontime_to_voxco\"].dt.total_seconds()\n",
        "metrics[\"ontime_to_voxco\"] = metrics[\"ontime_to_voxco\"]/60\n",
        "# Diff between voxco end and ontime end\n",
        "metrics = metrics.assign(voxco_to_ontime=metrics[\"ontime_end\"] - metrics[\"vc_logout\"])\n",
        "metrics[\"voxco_to_ontime\"] = metrics[\"voxco_to_ontime\"].dt.total_seconds()\n",
        "metrics[\"voxco_to_ontime\"] = metrics[\"voxco_to_ontime\"]/60\n",
        "# Diff between ontime end and schedule end\n",
        "metrics = metrics.assign(ontime_to_schedule=metrics[\"sched_end\"] - metrics[\"ontime_end\"])\n",
        "metrics[\"ontime_to_schedule\"] = metrics[\"ontime_to_schedule\"].dt.total_seconds()\n",
        "metrics[\"ontime_to_schedule\"] = metrics[\"ontime_to_schedule\"] /60\n",
        "\n",
        "# \"sesh_dur\" to mins\n",
        "metrics[\"sesh_dur\"] = metrics[\"sesh_dur\"]/60\n",
        "# \"soat\" to mins\n",
        "metrics[\"soat\"] = metrics[\"soat\"]/60\n",
        "# \"talk_time\" to mins\n",
        "metrics[\"talk_time\"] = metrics[\"talk_time\"]/60\n",
        "# \"waiting_time\" to mins\n",
        "metrics[\"waiting_time\"] = metrics[\"waiting_time\"]/60\n",
        "# \"pause_time\" to mins\n",
        "metrics[\"pause_time\"] = metrics[\"pause_time\"]/60\n",
        "# \"review_time\" to mins\n",
        "metrics[\"review_time\"] = metrics[\"review_time\"]/60\n",
        "# \"schedule_duration\" to mins\n",
        "metrics = metrics.assign(schedule_duration=metrics[\"sched_end\"] - metrics[\"sched_start\"])\n",
        "metrics[\"schedule_duration\"] = metrics[\"schedule_duration\"].dt.total_seconds()\n",
        "metrics[\"schedule_duration\"] = metrics[\"schedule_duration\"] / 60\n",
        "# Work Rate\n",
        "metrics = metrics.assign(work_rate=metrics[\"ontime_duration\"] / metrics[\"schedule_duration\"])\n",
        "# Absence Rate\n",
        "metrics = metrics.assign(absence_rate=metrics[\"ontime_duration\"] / (metrics[\"schedule_duration\"])-1)\n",
        "# Potential Discrepancy\n",
        "metrics = metrics.assign(potential_discrepancy=metrics[\"schedule_duration\"] - metrics[\"sesh_dur\"])\n",
        "\n",
        "\n",
        "################################################################### Reorder table\n",
        "metrics = metrics[[\"full_name\",\n",
        "                   \"eid\",\n",
        "                   \"Job Title\",\n",
        "                   \"Division\",\n",
        "                   \"Status\",\n",
        "                   \"hire_date\",\n",
        "                   \"date\",\n",
        "                   \"potential_discrepancy\",\n",
        "                   \"work_rate\",\n",
        "                   \"absence_rate\",\n",
        "                   \"exception_count\",\n",
        "                   \"sched_start\",\n",
        "                   \"sched_project\",\n",
        "                   \"schedule_to_ontime\",\n",
        "                   \"ontime_start\",\n",
        "                   \"ontime_start_project\",\n",
        "                   \"ontime_to_voxco\",\n",
        "                   \"vc_login\",\n",
        "                   \"vc_login_project\",\n",
        "                   \"vc_logout\",\n",
        "                   \"vc_logout_project\",\n",
        "                   \"voxco_to_ontime\",\n",
        "                   \"ontime_end\",\n",
        "                   \"ontime_end_project\",\n",
        "                   \"ontime_to_schedule\",\n",
        "                   \"sched_end\",\n",
        "                   \"sched_project\",\n",
        "                   \"talk_time\",\n",
        "                   \"waiting_time\",\n",
        "                   \"pause_time\",\n",
        "                   \"review_time\",\n",
        "                   \"sesh_dur\",\n",
        "                   \"soat\",\n",
        "                   \"ontime_duration\",\n",
        "                   \"schedule_duration\",\n",
        "                   \"vc_session_count\",\n",
        "                   \"ontime_slice_count\",\n",
        "                   \"break_duration\",\n",
        "                   \"break_count\"]]\n",
        "################################################################### Pre-filters\n",
        "\n",
        "################################################################### Diagnostics\n",
        "print(metrics)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              full_name     eid           Job Title Division  Status            hire_date       date  potential_discrepancy  work_rate  absence_rate  exception_count         sched_start sched_project  schedule_to_ontime               ontime_start ontime_start_project  ontime_to_voxco                vc_login vc_login_project               vc_logout vc_logout_project  voxco_to_ontime                 ontime_end ontime_end_project  ontime_to_schedule           sched_end sched_project   talk_time  waiting_time  pause_time  review_time    sesh_dur        soat  ontime_duration  schedule_duration  vc_session_count  ontime_slice_count  break_duration  break_count\n",
            "0            Ross, Alex  100045  Research Associate      CRD  Active  2021-07-13 00:00:00 2021-09-29             231.866667   0.432000     -0.568000              0.0 2021-09-29 13:45:00       kf1001c           15.274074 2021-09-29 14:00:16.444414              kf1001c         3.053043 2021-09-29 14:03:19.627          KF1001C 2021-09-29 16:43:30.990           KF1001C         0.460618 2021-09-29 16:43:58.627076            kf1001c          196.022882 2021-09-29 20:00:00       kf1001c  136.883333      5.033333    1.566667          0.0  143.133333  143.483333            162.0              375.0               2.0                 3.0            15.0          1.0\n",
            "1           Ayala, Eric  100412             Monitor      CRD  Active  2019-10-21 00:00:00 2021-09-29             130.016667   0.804167     -0.195833              1.0 2021-09-29 10:00:00       cf1011p          100.259192 2021-09-29 11:40:15.551517              cf1008l         7.646308 2021-09-29 11:47:54.330       CF1008L_LL 2021-09-29 18:12:12.730      CF1011P_CELL        -1.319581 2021-09-29 18:10:53.555117            cf1011p          -10.892585 2021-09-29 18:00:00       cf1011p  251.050000     92.400000    5.650000          0.0  349.983333  349.100000            386.0              480.0               5.0                 7.0            27.0          2.0\n",
            "2         Luna, Rolando  100548       Sr. Team Lead      CRD  Active  2019-11-01 00:00:00 2021-09-29                    NaN   0.064444     -0.935556              1.0 2021-09-29 09:30:00         staff          190.866480 2021-09-29 12:40:51.988811              general              NaN                     NaT              NaN                     NaT               NaN              NaN 2021-09-29 13:10:04.381192            general          229.926980 2021-09-29 17:00:00         staff         NaN           NaN         NaN          NaN         NaN         NaN             29.0              450.0               NaN                 1.0            29.0          1.0\n",
            "3    Jankowiak, Michele  101367  Research Associate      CRD  Active  2020-02-06 00:00:00 2021-09-29              97.966667   1.019355      0.019355              0.0 2021-09-29 12:15:00       kf1001c           -2.111699 2021-09-29 12:12:53.298053              kf1001c        26.845082 2021-09-29 12:39:44.003      KF1001C_SOP 2021-09-29 20:10:23.440           KF1001C        -0.991158 2021-09-29 20:09:23.970527            kf1001c           -9.399509 2021-09-29 20:00:00       kf1001c  324.066667      9.566667    2.116667          0.0  367.033333  335.750000            474.0              465.0               5.0                 6.0            27.0          2.0\n",
            "4        Webb, Jeannett  101432  Research Associate      CRD  Active  2020-02-11 00:00:00 2021-09-29                    NaN   0.990196     -0.009804              0.0 2021-09-29 09:30:00        ft1038            1.354713 2021-09-29 09:31:21.282780               ft1038              NaN                     NaT              NaN                     NaT               NaN              NaN 2021-09-29 18:00:05.913084             ft1038           -0.098551 2021-09-29 18:00:00        ft1038         NaN           NaN         NaN          NaN         NaN         NaN            505.0              510.0               NaN                 7.0            26.0          2.0\n",
            "..                  ...     ...                 ...      ...     ...                  ...        ...                    ...        ...           ...              ...                 ...           ...                 ...                        ...                  ...              ...                     ...              ...                     ...               ...              ...                        ...                ...                 ...                 ...           ...         ...           ...         ...          ...         ...         ...              ...                ...               ...                 ...             ...          ...\n",
            "351   Solano, Christina   34316  Research Associate      CRD  Active  2019-02-27 00:00:00 2021-10-05                    NaN   0.995699     -0.004301              0.0 2021-10-05 10:15:00        ft1038           -3.102358 2021-10-05 10:11:53.858512               ft1038              NaN                     NaT              NaN                     NaT               NaN              NaN 2021-10-05 17:58:53.557703             ft1038            1.107372 2021-10-05 18:00:00        ft1038         NaN           NaN         NaN          NaN         NaN         NaN            463.0              465.0               NaN                 6.0            41.0          2.0\n",
            "352      Ramer, Aleshia   34374  Research Associate      CRD  Active  2019-02-27 00:00:00 2021-10-05              57.250000   1.002667      0.002667              0.0 2021-10-05 13:45:00       kf1001c           -4.248775 2021-10-05 13:40:45.073494              kf1001c        20.748892 2021-10-05 14:01:30.007          KF1001C 2021-10-05 19:59:52.120           KF1001C        -0.341900 2021-10-05 19:59:31.606028            kf1001c            0.473233 2021-10-05 20:00:00       kf1001c  295.116667     21.033333    3.166667          0.0  317.750000  319.316667            376.0              375.0               4.0                 7.0            31.0          3.0\n",
            "353      Mcbride, Jamie   34688           Team Lead      CRD  Active  2019-03-11 00:00:00 2021-10-05                    NaN   1.161290      0.161290              3.0 2021-10-05 08:15:00  nis-q3-voxco           22.349206 2021-10-05 08:37:20.952360         nis-q3-voxco              NaN                     NaT              NaN                     NaT               NaN              NaN 2021-10-05 17:37:20.952360       nis-q3-voxco          -97.349206 2021-10-05 16:00:00  nis-q3-voxco         NaN           NaN         NaN          NaN         NaN         NaN            540.0              465.0               NaN                 1.0             NaN          NaN\n",
            "354        Bonner, Glen   35198  Research Associate      CRD  Active  2019-04-01 00:00:00 2021-10-05                    NaN   1.002151      0.002151              0.0 2021-10-05 10:15:00        ft1038           -3.347041 2021-10-05 10:11:39.177538               ft1038              NaN                     NaT              NaN                     NaT               NaN              NaN 2021-10-05 18:00:25.617890             ft1038           -0.426965 2021-10-05 18:00:00        ft1038         NaN           NaN         NaN          NaN         NaN         NaN            466.0              465.0               NaN                 6.0            36.0          2.0\n",
            "355       Driver, Eddie      65  Research Associate      CRD  Active  2007-09-02 00:00:00 2021-10-05              54.833333   0.995699     -0.004301              0.0 2021-10-05 10:15:00       cf1011q           -0.555893 2021-10-05 10:14:26.646446              cf1011p         9.777776 2021-10-05 10:24:13.313     CF1011P_CELL 2021-10-05 17:57:50.870        CF1011Q_LL         2.745828 2021-10-05 18:00:35.619665            cf1011q           -0.593661 2021-10-05 18:00:00       cf1011q  283.250000    112.966667   14.533333          0.0  410.166667  410.750000            463.0              465.0               5.0                 8.0            30.0          2.0\n",
            "\n",
            "[356 rows x 39 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7oTUk3fhRjR"
      },
      "source": [
        "# Concern List"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w56urH1yhVuu",
        "outputId": "f6e2c7e8-e369-4271-c3d3-d7ea93d03186"
      },
      "source": [
        "# This code block produces a list of concerning circumstances for Workforce Management to address\n",
        "# The first part establishes some parameters for the concerns list\n",
        "# The second part creates the list\n",
        "\n",
        "#Parameters\n",
        "#How many exceptions trigger an event?\n",
        "## The first standard deviation of the mean rounded plus one\n",
        "exception_trigger = abs(round(metrics[\"exception_count\"].std())) + 1\n",
        "# What defines a concerning discrepancy?\n",
        "## Greater than the absolute value of one standard deviation from the mean?\n",
        "discrepancy_trigger = abs(round(metrics[\"potential_discrepancy\"].std()))\n",
        "# Work Rate\n",
        "work_rate_trigger = 0.7\n",
        "# Schedule to Ontime\n",
        "sched_to_ontime_trigger = 5\n",
        "\n",
        "\n",
        "\n",
        "# Flagger\n",
        "\n",
        "## Exceptions\n",
        "ex = metrics[metrics[\"exception_count\"] >= exception_trigger]\n",
        "ex[\"exception_count\"] = ex[\"exception_count\"].astype(\"int64\")\n",
        "ex = ex.assign(message=\"Employee has \"+ex[\"exception_count\"].astype(\"str\")+\" exceptions. \"+(ex[\"exception_count\"]-(exception_trigger-1)).astype(\"str\")+\" more than allowance.\")\n",
        "ex = ex[[\"full_name\",\"eid\",\"date\",\"message\"]]\n",
        "\n",
        "# Discrepancy\n",
        "di = metrics[abs(metrics[\"potential_discrepancy\"]) > discrepancy_trigger]\n",
        "di = di.assign(message=\"Employee has \"+round(di[\"potential_discrepancy\"]).astype(\"int64\").astype(\"str\")+\" discrepancy minutes. \"+\"The parameter is \"+str(discrepancy_trigger)+\" minutes.\")\n",
        "di = di[[\"full_name\",\"eid\",\"date\",\"message\"]]\n",
        "\n",
        "# Work Rate\n",
        "\n",
        "\n",
        "\n",
        "# Schedule to Ontime\n",
        "so = metrics[abs(metrics[\"schedule_to_ontime\"])>sched_to_ontime_trigger]\n",
        "so = so.assign(message=\"Employee has exceeded the \" + str(sched_to_ontime_trigger) + \" minute schedule to ontime trigger by \" + str(metrics[\"schedule_to_ontime\"] - sched_to_ontime_trigger) + \" minutes.\" )\n",
        "so = so[[\"full_name\",\"eid\",\"date\",\"message\"]]\n",
        "print(so.head())\n",
        "\n",
        "\n",
        "# Ontime to Voxco\n",
        "\n",
        "\n",
        "\n",
        "# Voxco to Ontime\n",
        "\n",
        "\n",
        "\n",
        "# Ontime to Schedule\n",
        "\n",
        "\n",
        "\n",
        "# Too many breaks\n",
        "\n",
        "\n",
        "\n",
        "# Too many break minutes\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Concerns\n",
        "concerns = pd.concat([ex,di,so])\n",
        "print(concerns.head())\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         full_name     eid       date                                            message\n",
            "0       Ross, Alex  100045 2021-09-29  Employee has exceeded the 5 minute schedule to...\n",
            "1      Ayala, Eric  100412 2021-09-29  Employee has exceeded the 5 minute schedule to...\n",
            "2    Luna, Rolando  100548 2021-09-29  Employee has exceeded the 5 minute schedule to...\n",
            "9   Rascon, Orlena  102713 2021-09-29  Employee has exceeded the 5 minute schedule to...\n",
            "11  Tyrell, Shyann  102904 2021-09-29  Employee has exceeded the 5 minute schedule to...\n",
            "               full_name     eid       date                                            message\n",
            "10  Betancourt, Jennifer  102872 2021-09-29  Employee has 2 exceptions. 1 more than allowance.\n",
            "85          Mayne, Kelly  105124 2021-09-30  Employee has 3 exceptions. 2 more than allowance.\n",
            "86          Mayne, Kelly  105124 2021-09-30  Employee has 3 exceptions. 2 more than allowance.\n",
            "87    Ifopo, Christopher  105171 2021-09-30  Employee has 2 exceptions. 1 more than allowance.\n",
            "88    Ifopo, Christopher  105171 2021-09-30  Employee has 2 exceptions. 1 more than allowance.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jw9snEuRx17I"
      },
      "source": [
        "# Concerns Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9p5PJd_x1Eg",
        "outputId": "7f8b9911-c44c-4700-8137-bbb8905ee92a"
      },
      "source": [
        "concernsSummary = concerns.groupby([\"full_name\",\"eid\"]).size()\n",
        "print(concernsSummary.head())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "full_name         eid   \n",
            "0                 105380    1\n",
            "Ayala, Eric       100412    8\n",
            "Bailey, Geneva    105318    2\n",
            "Belt, Tamara      23928     5\n",
            "Benitez, Minerva  105478    3\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zlSwHHPp4CG"
      },
      "source": [
        "## Sample code for creating an excel file with multiple tabs\n",
        "```\n",
        "with pd.ExcelWriter('two_frames_one_tab.xlsx', engine='xlsxwriter') as writer:\n",
        "    df_first.to_excel(writer, sheet_name='first_tab', index=False)\n",
        "    df_second.to_excel(writer, sheet_name='second_tab', index=False)\n",
        "```\n",
        "## How to download an excel file\n",
        "files.download('example.xlsx') invokes a browsere download of the file to the local machine.\n",
        "```\n",
        "from google.colab import files\n",
        "\n",
        "with open('example.txt', 'w') as f:\n",
        "  f.write('some content')\n",
        "\n",
        "files.download('example.txt')\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxO-WHmzrDFK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "02e9dfb2-f7bd-4c23-aa50-dee7dc3ed777"
      },
      "source": [
        "# Now, make an excel doc with all the data in it and download\n",
        "with pd.ExcelWriter('Analysis_Engine.xlsx',\n",
        "                    datetime_format = 'YYYY-MM-DD HH:MM:SS') as writer:\n",
        "                    # Must make dates Timezone unaware!\n",
        "                    # RAData[\"Start\"] = RAData[\"Start\"].dt.tz_localize(None\n",
        "                    # RAData[\"End\"] = RAData[\"End\"].dt.tz_localize(None)\n",
        "  employee.to_excel(writer, sheet_name='employeeFile', index=False)\n",
        "  excep.to_excel(writer, sheet_name='exceptionList', index=False)\n",
        "  sched.to_excel(writer, sheet_name='schedule', index=False)\n",
        "  sesh.to_excel(writer, sheet_name='voxcoSessions', index=False)\n",
        "  sl.to_excel(writer, sheet_name='onTimeSlices', index=False)\n",
        "  metrics.to_excel(writer,sheet_name='metrics',index=False)\n",
        "  concerns.to_excel(writer,sheet_name='concerns',index=False)\n",
        "  concernsSummary.to_excel(writer,sheet_name='concernSummary',index=False)\n",
        "#Download Step\n",
        "files.download('Analysis_Engine.xlsx')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_03c89fbe-d4e3-4a8a-b823-15d5461474b9\", \"Analysis_Engine.xlsx\", 593104)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}